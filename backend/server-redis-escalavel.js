const express = require('express');
const cors = require('cors');
const bcrypt = require('bcrypt');
const jwt = require('jsonwebtoken');
const { v4: uuidv4 } = require('uuid');
const { Pool } = require('pg');
const redis = require('redis');
const rateLimit = require('express-rate-limit');
const compression = require('compression');
const winston = require('winston');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3001;

// ğŸš€ LOGGING ESTRUTURADO AVANÃ‡ADO
const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    })
  ],
});

// ğŸ” ENVIRONMENT VARIABLES SEGURAS
const {
  DATABASE_URL = "postgresql://postgres.lxatittpiiufvubyggzb:obm101264@aws-0-sa-east-1.pooler.supabase.com:6543/postgres",
  JWT_SECRET = 'arcflow-jwt-secret-super-secure-key-2024-development',
  REDIS_URL = 'redis://localhost:6379',
  NODE_ENV = 'development'
} = process.env;

// ğŸ’¾ CONNECTION POOLING OTIMIZADO - 10K USUÃRIOS
const pool = new Pool({
  connectionString: DATABASE_URL,
  max: 30,                      // 30 conexÃµes mÃ¡ximas
  min: 5,                       // 5 conexÃµes sempre ativas
  idleTimeoutMillis: 30000,     // 30s timeout
  connectionTimeoutMillis: 2000, // 2s connection timeout
  ssl: false
});

// âš¡ REDIS CLIENT - CACHE INTELIGENTE
const redisClient = redis.createClient({
  url: REDIS_URL
});

// ğŸ¯ CONFIGURAÃ‡Ã•ES DE CACHE
const CACHE_TIMES = {
  CLIENTES: 300,      // 5 minutos
  CPF_CHECK: 1800,    // 30 minutos
  USER_PROFILE: 900,  // 15 minutos
  BRIEFINGS: 3600     // 1 hora
};

// ğŸ› ï¸ HELPER FUNCTIONS PARA CACHE
const getCacheKey = (prefix, ...parts) => {
  return `arcflow:${prefix}:${parts.join(':')}`;
};

const getFromCache = async (key) => {
  try {
    if (!redisClient.isReady) return null;
    const cached = await redisClient.get(key);
    return cached ? JSON.parse(cached) : null;
  } catch (error) {
    logger.warn('âš ï¸ Erro ao ler cache:', error.message);
    return null;
  }
};

const setCache = async (key, data, ttl = 300) => {
  try {
    if (!redisClient.isReady) return;
    await redisClient.setEx(key, ttl, JSON.stringify(data));
  } catch (error) {
    logger.warn('âš ï¸ Erro ao salvar cache:', error.message);
  }
};

const invalidateCache = async (pattern) => {
  try {
    if (!redisClient.isReady) return;
    const keys = await redisClient.keys(pattern);
    if (keys.length > 0) {
      await redisClient.del(keys);
    }
  } catch (error) {
    logger.warn('âš ï¸ Erro ao invalidar cache:', error.message);
  }
};

// ğŸ›¡ï¸ RATE LIMITING GRANULAR
const clientesLimiter = rateLimit({
  windowMs: 1 * 60 * 1000,
  max: 100,
  keyGenerator: (req) => `clientes:${req.user?.id || req.ip}`,
  message: {
    error: 'Muitas operaÃ§Ãµes de clientes. Tente em 1 minuto.',
    code: 'CLIENTES_RATE_LIMIT'
  }
});

const cpfLimiter = rateLimit({
  windowMs: 1 * 60 * 1000,
  max: 30,
  keyGenerator: (req) => `cpf:${req.user?.id || req.ip}`,
  message: {
    error: 'Muitas verificaÃ§Ãµes de CPF. Tente em 1 minuto.',
    code: 'CPF_RATE_LIMIT'
  }
});

const authLimiter = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 5,
  keyGenerator: (req) => `auth:${req.body.email || req.ip}`,
  message: {
    error: 'Muitas tentativas de login. Tente em 15 minutos.',
    code: 'AUTH_RATE_LIMIT'
  }
});

// ğŸ”§ MIDDLEWARE
app.use(compression({ level: 6 }));
app.use(cors());
app.use(express.json({ limit: '10mb' }));

// ğŸ¥ HEALTH CHECK ULTRA COMPLETO
app.get('/health', async (req, res) => {
  const health = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    version: '2.0.0-redis',
    services: {}
  };
  
  // Test PostgreSQL
  try {
    const start = Date.now();
    await pool.query('SELECT 1');
    health.services.database = {
      status: 'ok',
      responseTime: `${Date.now() - start}ms`,
      connections: {
        total: pool.totalCount,
        idle: pool.idleCount,
        waiting: pool.waitingCount
      }
    };
  } catch (error) {
    health.services.database = {
      status: 'error',
      error: error.message
    };
    health.status = 'degraded';
  }
  
  // Test Redis
  try {
    const start = Date.now();
    await redisClient.ping();
    health.services.redis = {
      status: 'ok',
      responseTime: `${Date.now() - start}ms`,
      connected: redisClient.isReady
    };
  } catch (error) {
    health.services.redis = {
      status: 'error',
      error: error.message,
      connected: false
    };
  }
  
  const statusCode = health.status === 'ok' ? 200 : 503;
  res.status(statusCode).json(health);
});

// ğŸ” MIDDLEWARE DE AUTENTICAÃ‡ÃƒO COM CACHE
const authenticateToken = async (req, res, next) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1];

  if (!token) {
    return res.status(401).json({ 
      error: 'Token de acesso requerido',
      code: 'TOKEN_REQUIRED' 
    });
  }

  try {
    const decoded = jwt.verify(token, JWT_SECRET);
    
    // ğŸ¯ Buscar do cache primeiro
    const cacheKey = getCacheKey('user', decoded.id);
    let user = await getFromCache(cacheKey);
    
    if (!user) {
      // Se nÃ£o estiver no cache, buscar do banco
      const result = await pool.query('SELECT * FROM usuarios WHERE id = $1', [decoded.id]);
      if (result.rows.length === 0) {
        return res.status(401).json({ 
          error: 'UsuÃ¡rio nÃ£o encontrado',
          code: 'USER_NOT_FOUND' 
        });
      }
      
      user = result.rows[0];
      // Cachear por 15 minutos
      await setCache(cacheKey, user, CACHE_TIMES.USER_PROFILE);
    }
    
    req.user = user;
    next();
  } catch (error) {
    logger.warn('Token invÃ¡lido', { error: error.message });
    return res.status(403).json({ 
      error: 'Token invÃ¡lido',
      code: 'INVALID_TOKEN' 
    });
  }
};

// ğŸ“‹ API CLIENTES COM CACHE INTELIGENTE
app.get('/api/clientes', authenticateToken, clientesLimiter, async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { page = 1, limit = 50, search = '' } = req.query;
    const offset = (page - 1) * limit;
    const escritorioId = req.user.escritorio_id;
    
    // ğŸ¯ Cache key Ãºnica para paginaÃ§Ã£o e busca
    const cacheKey = getCacheKey('clientes', escritorioId, page, limit, search);
    
    // Tentar buscar do cache primeiro
    let result = await getFromCache(cacheKey);
    
    if (!result) {
      // Se nÃ£o estiver no cache, buscar do banco
      let query = `
        SELECT 
          id, nome, email, telefone, cpf, cnpj, tipo_pessoa,
          endereco, cidade, estado, cep, observacoes,
          created_at, updated_at
        FROM clientes 
        WHERE escritorio_id = $1 AND ativo = true
      `;
      
      let queryParams = [escritorioId];
      let paramIndex = 2;
      
      if (search) {
        query += ` AND (nome ILIKE $${paramIndex} OR email ILIKE $${paramIndex})`;
        queryParams.push(`%${search}%`);
        paramIndex++;
      }
      
      query += ` ORDER BY nome ASC LIMIT $${paramIndex} OFFSET $${paramIndex + 1}`;
      queryParams.push(limit, offset);
      
      let countQuery = `SELECT COUNT(*) as total FROM clientes WHERE escritorio_id = $1 AND ativo = true`;
      let countParams = [escritorioId];
      
      if (search) {
        countQuery += ` AND (nome ILIKE $2 OR email ILIKE $2)`;
        countParams.push(`%${search}%`);
      }
      
      const [clientesResult, countResult] = await Promise.all([
        pool.query(query, queryParams),
        pool.query(countQuery, countParams)
      ]);
      
      result = {
        clientes: clientesResult.rows,
        pagination: {
          page: parseInt(page),
          limit: parseInt(limit),
          total: parseInt(countResult.rows[0].total),
          pages: Math.ceil(countResult.rows[0].total / limit)
        },
        cached: false
      };
      
      // Cachear por 5 minutos
      await setCache(cacheKey, result, CACHE_TIMES.CLIENTES);
    } else {
      result.cached = true;
    }
    
    logger.info('âœ… Clientes listados', {
      escritorioId,
      count: result.clientes.length,
      cached: result.cached,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.json(result);
    
  } catch (error) {
    logger.error('âŒ Erro ao listar clientes', {
      error: error.message,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.status(500).json({
      error: 'Erro interno do servidor',
      code: 'INTERNAL_ERROR'
    });
  }
});

// ğŸ†” VERIFICAÃ‡ÃƒO CPF COM CACHE
app.get('/api/clientes/verificar-cpf/:cpf', authenticateToken, cpfLimiter, async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { cpf } = req.params;
    const cpfLimpo = cpf.replace(/[^\d]/g, '');
    const escritorioId = req.user.escritorio_id;
    
    // Cache key para CPF especÃ­fico
    const cacheKey = getCacheKey('cpf', escritorioId, cpfLimpo);
    
    // Tentar buscar do cache primeiro
    let exists = await getFromCache(cacheKey);
    
    if (exists === null) {
      // Se nÃ£o estiver no cache, buscar do banco
      const result = await pool.query(
        'SELECT id FROM clientes WHERE escritorio_id = $1 AND REPLACE(REPLACE(REPLACE(cpf, \'.\', \'\'), \'-\', \'\'), \' \', \'\') = $2 AND ativo = true',
        [escritorioId, cpfLimpo]
      );
      
      exists = result.rows.length > 0;
      
      // Cachear por 30 minutos
      await setCache(cacheKey, exists, CACHE_TIMES.CPF_CHECK);
    }
    
    logger.info('âœ… CPF verificado', {
      cpf: cpfLimpo,
      exists,
      cached: exists !== null,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.json({ exists });
    
  } catch (error) {
    logger.error('âŒ Erro ao verificar CPF', {
      error: error.message,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.status(500).json({
      error: 'Erro interno do servidor',
      code: 'INTERNAL_ERROR'
    });
  }
});

// ğŸ” LOGIN COM CACHE
app.post('/api/auth/login', authLimiter, async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { email, password } = req.body;
    
    if (!email || !password) {
      return res.status(400).json({
        error: 'Email e senha sÃ£o obrigatÃ³rios',
        code: 'MISSING_CREDENTIALS'
      });
    }
    
    const result = await pool.query(
      'SELECT * FROM usuarios WHERE email = $1 AND ativo = true',
      [email.toLowerCase()]
    );
    
    if (result.rows.length === 0) {
      logger.warn('âŒ Login - usuÃ¡rio nÃ£o encontrado', { email });
      return res.status(401).json({
        error: 'Credenciais invÃ¡lidas',
        code: 'INVALID_CREDENTIALS'
      });
    }
    
    const user = result.rows[0];
    
    const validPassword = await bcrypt.compare(password, user.password);
    if (!validPassword) {
      logger.warn('âŒ Login - senha incorreta', { email });
      return res.status(401).json({
        error: 'Credenciais invÃ¡lidas',
        code: 'INVALID_CREDENTIALS'
      });
    }
    
    const token = jwt.sign(
      {
        id: user.id,
        email: user.email,
        nome: user.nome,
        role: user.role,
        escritorioId: user.escritorio_id
      },
      JWT_SECRET,
      { expiresIn: '15m' }
    );
    
    // Cachear usuÃ¡rio apÃ³s login
    const cacheKey = getCacheKey('user', user.id);
    await setCache(cacheKey, user, CACHE_TIMES.USER_PROFILE);
    
    logger.info('âœ… Login realizado', {
      userId: user.id,
      email: user.email,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.json({
      message: 'Login realizado com sucesso',
      user: {
        id: user.id,
        nome: user.nome,
        email: user.email,
        role: user.role,
        escritorioId: user.escritorio_id
      },
      token
    });
    
  } catch (error) {
    logger.error('âŒ Erro no login', {
      error: error.message,
      responseTime: `${Date.now() - startTime}ms`
    });
    
    res.status(500).json({
      error: 'Erro interno do servidor',
      code: 'INTERNAL_ERROR'
    });
  }
});

// ğŸš€ INICIALIZAÃ‡ÃƒO COMPLETA
const initServer = async () => {
  try {
    // Conectar Redis
    redisClient.on('connect', () => logger.info('âœ… Redis conectado com sucesso'));
    redisClient.on('error', (err) => logger.error('âŒ Redis erro:', err));
    
    try {
      await redisClient.connect();
      logger.info('âœ… Redis client inicializado');
    } catch (error) {
      logger.warn('âš ï¸ Redis nÃ£o disponÃ­vel, continuando sem cache:', error.message);
    }
    
    // Conectar PostgreSQL
    await pool.connect();
    logger.info('âœ… PostgreSQL pool inicializado', {
      max: pool.options.max,
      min: pool.options.min
    });
    
    // Iniciar servidor
    app.listen(PORT, () => {
      logger.info('ğŸš€ ArcFlow Backend REDIS ESCALÃVEL iniciado!', {
        port: PORT,
        environment: NODE_ENV,
        redis: redisClient.isReady ? 'âœ… Conectado' : 'âŒ Desconectado',
        features: [
          'âœ… PostgreSQL Pool (5-30 conexÃµes)',
          'âœ… Redis Cache Inteligente',
          'âœ… Rate Limiting Granular',
          'âœ… Logs Estruturados',
          'âœ… Health Checks Completos',
          'ğŸ¯ PRONTO PARA 10.000 USUÃRIOS SIMULTÃ‚NEOS!'
        ]
      });
    });
    
  } catch (error) {
    logger.error('âŒ Erro ao inicializar servidor:', error);
    process.exit(1);
  }
};

// ğŸ”„ GRACEFUL SHUTDOWN
process.on('SIGTERM', async () => {
  logger.info('ğŸ“¡ SIGTERM recebido, encerrando servidor graciosamente...');
  
  try {
    await pool.end();
    await redisClient.quit();
    logger.info('âœ… Todas as conexÃµes fechadas com sucesso');
  } catch (error) {
    logger.error('âŒ Erro ao fechar conexÃµes:', error);
  }
  
  process.exit(0);
});

// ğŸ¬ INICIAR SERVIDOR
initServer();

module.exports = app; 